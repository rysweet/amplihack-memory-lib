{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"amplihack-memory-lib","text":"<p>Standalone memory system for goal-seeking AI agents.</p> <p>amplihack-memory-lib provides a graph-based memory system built on Kuzu that gives AI agents persistent, structured memory with cognitive science-inspired categories. It supports episodic, semantic, procedural, prospective, and working memory -- enabling agents to learn, recall, and reason across sessions.</p>"},{"location":"#quick-start","title":"Quick Start","text":""},{"location":"#installation","title":"Installation","text":"<pre><code># Using uv (recommended)\nuv pip install -e .\n\n# Using pip\npip install -e .\n</code></pre>"},{"location":"#basic-usage","title":"Basic Usage","text":"<pre><code>from amplihack_memory import HierarchicalMemory\n\n# Create a memory instance for your agent\nmem = HierarchicalMemory(\"my-agent\", \"/tmp/my_agent_memory\")\n\n# Store knowledge\nnode_id = mem.store_knowledge(\n    content=\"Python 3.12 introduced type parameter syntax\",\n    concept=\"python-features\",\n    confidence=0.95,\n    tags=[\"python\", \"typing\"],\n)\n\n# Retrieve related knowledge via Graph RAG\nsubgraph = mem.retrieve_subgraph(\"python type features\")\nprint(subgraph.to_llm_context())\n</code></pre>"},{"location":"#six-type-cognitive-memory","title":"Six-Type Cognitive Memory","text":"<pre><code>from amplihack_memory import CognitiveMemory\n\ncog = CognitiveMemory(\"my-agent\", \"/tmp/cog_memory\")\n\n# Sensory: short-lived observations\ncog.record_sensory(\"text\", \"User asked about deployment\", ttl_seconds=300)\n\n# Working: active task context (bounded capacity)\ncog.push_working(\"goal\", \"Deploy v2.0 to staging\", task_id=\"deploy-task\")\n\n# Episodic: autobiographical events\ncog.store_episode(\"Deployment succeeded on staging\", source_label=\"ci-run\")\n\n# Semantic: distilled facts\ncog.store_fact(\"staging\", \"Staging environment uses port 8080\", confidence=0.9)\n\n# Procedural: reusable procedures\ncog.store_procedure(\"deploy\", [\"Build image\", \"Push to registry\", \"Update k8s\"])\n\n# Prospective: future trigger-action pairs\ncog.store_prospective(\n    \"Alert on failure\",\n    trigger_condition=\"deployment failed\",\n    action_on_trigger=\"Notify #ops channel\",\n)\n</code></pre>"},{"location":"#documentation","title":"Documentation","text":"Document Description Architecture Package structure, core components, design philosophy, data flow Hierarchical Memory Graph-based memory with 5 categories, SUPERSEDES/TRANSITIONED_TO edges, Graph RAG Cognitive Memory Six-type cognitive memory system (sensory, working, episodic, semantic, procedural, prospective) Kuzu Backend How the Kuzu graph database works, schema, query patterns API Reference Complete API reference for all public classes Extending Custom backends, new edge types, custom classifiers, integration patterns"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Graph-based knowledge storage -- Facts stored as nodes, relationships as edges, enabling Graph RAG retrieval</li> <li>Cognitive memory categories -- Sensory, working, episodic, semantic, procedural, and prospective memory types</li> <li>Auto-classification -- Rule-based classifier assigns memory categories automatically</li> <li>Temporal reasoning -- SUPERSEDES and TRANSITIONED_TO edges track how knowledge evolves over time</li> <li>Entity-centric retrieval -- Extract entity names for targeted graph traversal</li> <li>Contradiction detection -- Automatically detect conflicting numerical values between facts</li> <li>Similarity-based Graph RAG -- Jaccard-based text similarity creates SIMILAR_TO edges for traversal</li> <li>Dual backend -- Kuzu graph database (default) with SQLite fallback</li> <li>Security layer -- Capability-based access control, credential scrubbing, query cost validation</li> <li>Zero dependencies on amplihack -- Fully standalone, requires only <code>kuzu</code> and Python stdlib</li> </ul>"},{"location":"#architecture-at-a-glance","title":"Architecture at a Glance","text":"<pre><code>amplihack_memory/\n    __init__.py              # Public API exports\n    hierarchical_memory.py   # HierarchicalMemory (Graph RAG)\n    cognitive_memory.py      # CognitiveMemory (6-type cognitive)\n    memory_types.py          # Dataclasses for cognitive memory types\n    similarity.py            # Text similarity (Jaccard, reranking)\n    entity_extraction.py     # Entity name extraction\n    contradiction.py         # Contradiction detection\n    connector.py             # MemoryConnector (backend factory)\n    experience.py            # Experience data model\n    store.py                 # ExperienceStore (high-level)\n    security.py              # Security layer\n    pattern_recognition.py   # Pattern detection\n    semantic_search.py       # TF-IDF relevance scoring\n    exceptions.py            # Custom exceptions\n    backends/\n        base.py              # Abstract MemoryBackend\n        kuzu_backend.py      # Kuzu graph backend\n        sqlite_backend.py    # SQLite fallback backend\n</code></pre>"},{"location":"api_reference/","title":"API Reference","text":"<p>Complete API reference for all public classes and functions in <code>amplihack_memory</code>.</p>"},{"location":"api_reference/#hierarchicalmemory","title":"HierarchicalMemory","text":"<pre><code>from amplihack_memory import HierarchicalMemory\n</code></pre>"},{"location":"api_reference/#constructor","title":"Constructor","text":"<pre><code>HierarchicalMemory(\n    agent_name: str,\n    db_path: str | Path | None = None,\n)\n</code></pre> Parameter Type Default Description <code>agent_name</code> <code>str</code> required Agent identifier (alphanumeric + hyphens/underscores, 1-64 chars) <code>db_path</code> <code>str \\| Path \\| None</code> <code>None</code> Path to Kuzu database directory. Defaults to <code>~/.amplihack/hierarchical_memory/&lt;agent_name&gt;</code>"},{"location":"api_reference/#methods","title":"Methods","text":""},{"location":"api_reference/#store_knowledge","title":"store_knowledge","text":"<pre><code>store_knowledge(\n    content: str,\n    concept: str = \"\",\n    confidence: float = 0.8,\n    category: MemoryCategory | None = None,\n    source_id: str = \"\",\n    tags: list[str] | None = None,\n    temporal_metadata: dict | None = None,\n) -&gt; str\n</code></pre> <p>Store a knowledge node. Returns the <code>node_id</code> (UUID string).</p>"},{"location":"api_reference/#store_episode","title":"store_episode","text":"<pre><code>store_episode(content: str, source_label: str = \"\") -&gt; str\n</code></pre> <p>Store an episodic memory node. Returns the <code>episode_id</code>.</p>"},{"location":"api_reference/#retrieve_subgraph","title":"retrieve_subgraph","text":"<pre><code>retrieve_subgraph(\n    query: str,\n    max_nodes: int = 20,\n    similarity_threshold: float = 0.3,\n) -&gt; KnowledgeSubgraph\n</code></pre> <p>Retrieve a subgraph of related knowledge via Graph RAG.</p>"},{"location":"api_reference/#get_all_knowledge","title":"get_all_knowledge","text":"<pre><code>get_all_knowledge(limit: int = 50) -&gt; list[KnowledgeNode]\n</code></pre> <p>Get all knowledge nodes for this agent.</p>"},{"location":"api_reference/#export_graph","title":"export_graph","text":"<pre><code>export_graph() -&gt; dict\n</code></pre> <p>Export the entire graph as a serializable dict.</p>"},{"location":"api_reference/#import_graph","title":"import_graph","text":"<pre><code>import_graph(data: dict) -&gt; None\n</code></pre> <p>Import a graph from a previously exported dict.</p>"},{"location":"api_reference/#store_fact-alias","title":"store_fact (alias)","text":"<pre><code>store_fact(content: str, concept: str = \"\", confidence: float = 0.8, **kwargs) -&gt; str\n</code></pre> <p>Protocol-compatible alias for <code>store_knowledge()</code>.</p>"},{"location":"api_reference/#search_facts-alias","title":"search_facts (alias)","text":"<pre><code>search_facts(query: str, max_nodes: int = 20, **kwargs) -&gt; list[dict]\n</code></pre> <p>Protocol-compatible wrapper around <code>retrieve_subgraph()</code>. Returns list of dicts.</p>"},{"location":"api_reference/#get_all_facts-alias","title":"get_all_facts (alias)","text":"<pre><code>get_all_facts(limit: int = 50) -&gt; list[dict]\n</code></pre> <p>Protocol-compatible wrapper around <code>get_all_knowledge()</code>. Returns list of dicts.</p>"},{"location":"api_reference/#close","title":"close","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Release the Kuzu database connection.</p>"},{"location":"api_reference/#cognitivememory","title":"CognitiveMemory","text":"<pre><code>from amplihack_memory import CognitiveMemory\n</code></pre>"},{"location":"api_reference/#constructor_1","title":"Constructor","text":"<pre><code>CognitiveMemory(\n    agent_name: str,\n    db_path: str | Path,\n)\n</code></pre> Parameter Type Description <code>agent_name</code> <code>str</code> Agent identifier (cannot be empty) <code>db_path</code> <code>str \\| Path</code> Path to Kuzu database directory"},{"location":"api_reference/#sensory-memory-methods","title":"Sensory Memory Methods","text":"Method Signature Returns <code>record_sensory</code> <code>(modality: str, raw_data: str, ttl_seconds: int = 300) -&gt; str</code> <code>node_id</code> <code>get_recent_sensory</code> <code>(limit: int = 10) -&gt; list[SensoryItem]</code> Non-expired items <code>attend_to_sensory</code> <code>(sensory_id: str, reason: str) -&gt; str \\| None</code> Episodic <code>node_id</code> or <code>None</code> <code>prune_expired_sensory</code> <code>() -&gt; int</code> Count pruned"},{"location":"api_reference/#working-memory-methods","title":"Working Memory Methods","text":"Method Signature Returns <code>push_working</code> <code>(slot_type: str, content: str, task_id: str, relevance: float = 1.0) -&gt; str</code> <code>node_id</code> <code>get_working</code> <code>(task_id: str) -&gt; list[WorkingMemorySlot]</code> Slots by relevance DESC <code>clear_working</code> <code>(task_id: str) -&gt; int</code> Count cleared"},{"location":"api_reference/#episodic-memory-methods","title":"Episodic Memory Methods","text":"Method Signature Returns <code>store_episode</code> <code>(content: str, source_label: str, temporal_index: int \\| None = None, metadata: dict \\| None = None) -&gt; str</code> <code>node_id</code> <code>get_episodes</code> <code>(limit: int = 20, include_compressed: bool = False) -&gt; list[EpisodicMemory]</code> Episodes by temporal_index DESC <code>consolidate_episodes</code> <code>(batch_size: int = 10, summarizer: Callable \\| None = None) -&gt; str \\| None</code> ConsolidatedEpisode <code>node_id</code> or <code>None</code>"},{"location":"api_reference/#semantic-memory-methods","title":"Semantic Memory Methods","text":"Method Signature Returns <code>store_fact</code> <code>(concept: str, content: str, confidence: float = 1.0, source_id: str = \"\", tags: list[str] \\| None = None, temporal_metadata: dict \\| None = None) -&gt; str</code> <code>node_id</code> <code>search_facts</code> <code>(query: str, limit: int = 10, min_confidence: float = 0.0) -&gt; list[SemanticFact]</code> Matching facts <code>get_all_facts</code> <code>(limit: int = 50) -&gt; list[SemanticFact]</code> All facts by confidence DESC"},{"location":"api_reference/#procedural-memory-methods","title":"Procedural Memory Methods","text":"Method Signature Returns <code>store_procedure</code> <code>(name: str, steps: list[str], prerequisites: list[str] \\| None = None, ...) -&gt; str</code> <code>node_id</code> <code>recall_procedure</code> <code>(query: str, limit: int = 5) -&gt; list[ProceduralMemory]</code> Matching procedures (usage_count incremented)"},{"location":"api_reference/#prospective-memory-methods","title":"Prospective Memory Methods","text":"Method Signature Returns <code>store_prospective</code> <code>(description: str, trigger_condition: str, action_on_trigger: str, priority: int = 1) -&gt; str</code> <code>node_id</code> <code>check_triggers</code> <code>(content: str) -&gt; list[ProspectiveMemory]</code> Triggered items <code>resolve_prospective</code> <code>(node_id: str) -&gt; None</code> --"},{"location":"api_reference/#other-methods","title":"Other Methods","text":"Method Signature Returns <code>get_statistics</code> <code>() -&gt; dict</code> Counts per memory type + total <code>close</code> <code>() -&gt; None</code> Release Kuzu connection"},{"location":"api_reference/#data-classes","title":"Data Classes","text":""},{"location":"api_reference/#knowledgenode","title":"KnowledgeNode","text":"<pre><code>from amplihack_memory import KnowledgeNode\n</code></pre> Field Type Default Description <code>node_id</code> <code>str</code> required UUID identifier <code>category</code> <code>MemoryCategory</code> required Memory category <code>content</code> <code>str</code> required Main text content <code>concept</code> <code>str</code> required Topic/concept label <code>confidence</code> <code>float</code> <code>0.8</code> Confidence score <code>source_id</code> <code>str</code> <code>\"\"</code> Provenance ID <code>created_at</code> <code>str</code> <code>\"\"</code> ISO timestamp <code>tags</code> <code>list[str]</code> <code>[]</code> Tags <code>metadata</code> <code>dict</code> <code>{}</code> Additional metadata"},{"location":"api_reference/#knowledgeedge","title":"KnowledgeEdge","text":"<pre><code>from amplihack_memory import KnowledgeEdge\n</code></pre> Field Type Default Description <code>source_id</code> <code>str</code> required Source node ID <code>target_id</code> <code>str</code> required Target node ID <code>relationship</code> <code>str</code> required Edge type <code>weight</code> <code>float</code> <code>1.0</code> Edge weight <code>metadata</code> <code>dict</code> <code>{}</code> Additional metadata"},{"location":"api_reference/#knowledgesubgraph","title":"KnowledgeSubgraph","text":"<pre><code>from amplihack_memory import KnowledgeSubgraph\n</code></pre> Field Type Default Description <code>nodes</code> <code>list[KnowledgeNode]</code> <code>[]</code> Knowledge nodes <code>edges</code> <code>list[KnowledgeEdge]</code> <code>[]</code> Knowledge edges <code>query</code> <code>str</code> <code>\"\"</code> Original query <p>Methods:</p> <ul> <li><code>to_llm_context(chronological: bool = False) -&gt; str</code> -- Format as LLM-readable text</li> </ul>"},{"location":"api_reference/#memorycategory-hierarchicalmemory","title":"MemoryCategory (HierarchicalMemory)","text":"<pre><code>from amplihack_memory.hierarchical_memory import MemoryCategory\n</code></pre> Value String <code>EPISODIC</code> <code>\"episodic\"</code> <code>SEMANTIC</code> <code>\"semantic\"</code> <code>PROCEDURAL</code> <code>\"procedural\"</code> <code>PROSPECTIVE</code> <code>\"prospective\"</code> <code>WORKING</code> <code>\"working\"</code>"},{"location":"api_reference/#memorycategory-cognitivememory","title":"MemoryCategory (CognitiveMemory)","text":"<pre><code>from amplihack_memory import MemoryCategory\n</code></pre> Value String <code>SENSORY</code> <code>\"sensory\"</code> <code>WORKING</code> <code>\"working\"</code> <code>EPISODIC</code> <code>\"episodic\"</code> <code>SEMANTIC</code> <code>\"semantic\"</code> <code>PROCEDURAL</code> <code>\"procedural\"</code> <code>PROSPECTIVE</code> <code>\"prospective\"</code>"},{"location":"api_reference/#experience-system","title":"Experience System","text":""},{"location":"api_reference/#experience","title":"Experience","text":"<pre><code>from amplihack_memory import Experience, ExperienceType\n</code></pre> Field Type Default Description <code>experience_type</code> <code>ExperienceType</code> required Type enum <code>context</code> <code>str</code> required Situation (max 500 chars) <code>outcome</code> <code>str</code> required Result (max 1000 chars) <code>confidence</code> <code>float</code> required 0.0-1.0 <code>timestamp</code> <code>datetime</code> <code>now()</code> When it occurred <code>experience_id</code> <code>str</code> auto-generated <code>exp_YYYYMMDD_HHMMSS_hash</code> <code>metadata</code> <code>dict</code> <code>{}</code> Structured data <code>tags</code> <code>list[str]</code> <code>[]</code> Tags <p>Methods:</p> <ul> <li><code>to_dict() -&gt; dict</code> -- Serialize to dictionary</li> <li><code>from_dict(data) -&gt; Experience</code> -- Class method to deserialize</li> </ul>"},{"location":"api_reference/#experiencetype","title":"ExperienceType","text":"Value String <code>SUCCESS</code> <code>\"success\"</code> <code>FAILURE</code> <code>\"failure\"</code> <code>PATTERN</code> <code>\"pattern\"</code> <code>INSIGHT</code> <code>\"insight\"</code>"},{"location":"api_reference/#experiencestore","title":"ExperienceStore","text":"<pre><code>from amplihack_memory import ExperienceStore\n</code></pre> <pre><code>ExperienceStore(\n    agent_name: str,\n    auto_compress: bool = True,\n    max_age_days: int | None = None,\n    max_experiences: int | None = None,\n    max_memory_mb: int = 100,\n    storage_path: Path | None = None,\n    backend: str = \"kuzu\",\n)\n</code></pre> Method Signature Description <code>add</code> <code>(experience: Experience) -&gt; str</code> Add with auto-management <code>search</code> <code>(query, experience_type, min_confidence, limit) -&gt; list[Experience]</code> Full-text search <code>get_statistics</code> <code>() -&gt; dict</code> Storage stats"},{"location":"api_reference/#memoryconnector","title":"MemoryConnector","text":"<pre><code>from amplihack_memory import MemoryConnector\n</code></pre> <pre><code>MemoryConnector(\n    agent_name: str,\n    storage_path: Path | None = None,\n    max_memory_mb: int = 100,\n    enable_compression: bool = True,\n    backend: str = \"kuzu\",\n)\n</code></pre> Method Signature Description <code>store_experience</code> <code>(experience: Experience) -&gt; str</code> Store experience <code>retrieve_experiences</code> <code>(limit, experience_type, min_confidence) -&gt; list[Experience]</code> Retrieve <code>search</code> <code>(query, experience_type, min_confidence, limit) -&gt; list[Experience]</code> Search <code>get_statistics</code> <code>() -&gt; dict</code> Stats <code>close</code> <code>() -&gt; None</code> Close connection <p>Supports context manager: <code>with MemoryConnector(...) as conn:</code></p>"},{"location":"api_reference/#shared-utilities","title":"Shared Utilities","text":""},{"location":"api_reference/#similarity","title":"Similarity","text":"<pre><code>from amplihack_memory import (\n    compute_similarity,\n    compute_word_similarity,\n    compute_tag_similarity,\n    rerank_facts_by_query,\n)\n</code></pre> Function Signature Description <code>compute_word_similarity</code> <code>(text_a: str, text_b: str) -&gt; float</code> Jaccard on tokenized words <code>compute_tag_similarity</code> <code>(tags_a: list[str], tags_b: list[str]) -&gt; float</code> Jaccard on tag lists <code>compute_similarity</code> <code>(node_a: dict, node_b: dict) -&gt; float</code> Weighted composite (0.5w + 0.2t + 0.3c) <code>rerank_facts_by_query</code> <code>(facts: list[dict], query: str, top_k: int = 0) -&gt; list[dict]</code> Rerank by query relevance"},{"location":"api_reference/#entity-extraction","title":"Entity Extraction","text":"<pre><code>from amplihack_memory import extract_entity_name\n</code></pre> <pre><code>extract_entity_name(content: str, concept: str = \"\") -&gt; str\n</code></pre> <p>Returns lowercase entity name or empty string.</p>"},{"location":"api_reference/#contradiction-detection","title":"Contradiction Detection","text":"<pre><code>from amplihack_memory import detect_contradiction\n</code></pre> <pre><code>detect_contradiction(\n    content_a: str, content_b: str,\n    concept_a: str = \"\", concept_b: str = \"\",\n) -&gt; dict\n</code></pre> <p>Returns <code>{\"contradiction\": True, \"conflicting_values\": \"...\"}</code> or empty dict.</p>"},{"location":"api_reference/#security","title":"Security","text":"<pre><code>from amplihack_memory import (\n    AgentCapabilities,\n    ScopeLevel,\n    CredentialScrubber,\n    QueryValidator,\n    SecureMemoryBackend,\n)\n</code></pre>"},{"location":"api_reference/#scopelevel","title":"ScopeLevel","text":"Value Description <code>SESSION_ONLY</code> Current session only <code>CROSS_SESSION_READ</code> Read from other sessions <code>CROSS_SESSION_WRITE</code> Write across sessions <code>GLOBAL_READ</code> Read all agents' memories <code>GLOBAL_WRITE</code> Write to any agent's memory"},{"location":"api_reference/#agentcapabilities","title":"AgentCapabilities","text":"<pre><code>AgentCapabilities(\n    scope: ScopeLevel,\n    allowed_experience_types: list[ExperienceType],\n    max_query_cost: int,\n    can_access_patterns: bool,\n    memory_quota_mb: int,\n)\n</code></pre>"},{"location":"api_reference/#credentialscrubber","title":"CredentialScrubber","text":"<pre><code>scrubber = CredentialScrubber()\nscrubbed_exp, was_scrubbed = scrubber.scrub_experience(experience)\nhas_creds = scrubber.contains_credentials(text)\n</code></pre>"},{"location":"api_reference/#securememorybackend","title":"SecureMemoryBackend","text":"<pre><code>secure = SecureMemoryBackend(store, capabilities)\nsecure.add_experience(experience)  # Enforces caps + scrubs\nsecure.search(query)               # Enforces type restrictions\n</code></pre>"},{"location":"api_reference/#exceptions","title":"Exceptions","text":"<pre><code>from amplihack_memory import (\n    MemoryError,               # Base exception\n    ExperienceNotFoundError,   # Experience not found\n    InvalidExperienceError,    # Validation failure\n    MemoryQuotaExceededError,  # Storage quota exceeded\n    SecurityViolationError,    # Security policy violation\n    QueryCostExceededError,    # Query too expensive\n)\n</code></pre>"},{"location":"architecture/","title":"Architecture","text":""},{"location":"architecture/#overview","title":"Overview","text":"<p>amplihack-memory-lib is organized into three layers, each building on the one below:</p> <pre><code>+------------------------------------------------------------+\n|                     Public API Layer                        |\n|  HierarchicalMemory  |  CognitiveMemory  |  ExperienceStore|\n+------------------------------------------------------------+\n|                   Shared Utilities Layer                    |\n|  similarity  |  entity_extraction  |  contradiction        |\n|  MemoryClassifier  |  pattern_recognition  |  security     |\n+------------------------------------------------------------+\n|                    Storage Backend Layer                    |\n|  MemoryConnector  -&gt;  KuzuBackend  |  SQLiteBackend        |\n+------------------------------------------------------------+\n|                     Kuzu / SQLite                           |\n+------------------------------------------------------------+\n</code></pre>"},{"location":"architecture/#core-components","title":"Core Components","text":""},{"location":"architecture/#hierarchicalmemory-graph-rag","title":"HierarchicalMemory (Graph RAG)","text":"<p>File: <code>hierarchical_memory.py</code></p> <p>The primary memory system for AI agents that need structured knowledge with relationships. It manages a Kuzu knowledge graph containing:</p> <ul> <li>SemanticMemory nodes -- Distilled facts with concept labels, confidence scores, tags, and entity names</li> <li>EpisodicMemory nodes -- Raw source content (episodes) with provenance labels</li> <li>SIMILAR_TO edges -- Computed via Jaccard text similarity at storage time</li> <li>DERIVES_FROM edges -- Link facts to their source episodes (provenance)</li> <li>SUPERSEDES edges -- Track temporal updates (newer fact replaces older)</li> <li>TRANSITIONED_TO edges -- Explicit value transition chains for temporal reasoning</li> </ul> <p>Key methods:</p> Method Purpose <code>store_knowledge()</code> Store a fact node, auto-classify, compute similarity edges <code>store_episode()</code> Store a raw episode node <code>retrieve_subgraph()</code> Graph RAG retrieval: keyword match + similarity traversal <code>get_all_knowledge()</code> Get all fact nodes for an agent <code>export_graph()</code> / <code>import_graph()</code> Serialize/deserialize the full graph <p>Protocol-compatible aliases (<code>store_fact</code>, <code>search_facts</code>, <code>get_all_facts</code>) provide interop with ExperienceStore consumers.</p>"},{"location":"architecture/#cognitivememory-six-type","title":"CognitiveMemory (Six-Type)","text":"<p>File: <code>cognitive_memory.py</code></p> <p>A higher-level memory system modeled after human cognition with six distinct memory types, each stored in its own Kuzu node table:</p> Memory Type Table Purpose Lifecycle Sensory <code>SensoryMemory</code> Raw short-lived observations Auto-expires via TTL Working <code>WorkingMemory</code> Active task context Bounded capacity (20 slots), evicts lowest relevance Episodic <code>EpisodicMemory</code> Autobiographical events Consolidatable into summaries Semantic <code>SemanticMemory</code> Distilled facts/knowledge Persistent, searchable by keyword Procedural <code>ProceduralMemory</code> Step-by-step procedures Usage-count tracked, searchable Prospective <code>ProspectiveMemory</code> Trigger-action pairs Pending -&gt; triggered -&gt; resolved <p>Relationship edges:</p> <ul> <li>SIMILAR_TO (SemanticMemory -&gt; SemanticMemory)</li> <li>DERIVES_FROM (SemanticMemory -&gt; EpisodicMemory)</li> <li>PROCEDURE_DERIVES_FROM (ProceduralMemory -&gt; EpisodicMemory)</li> <li>CONSOLIDATES (ConsolidatedEpisode -&gt; EpisodicMemory)</li> <li>ATTENDED_TO (SensoryMemory -&gt; EpisodicMemory)</li> </ul>"},{"location":"architecture/#experiencestore-legacysimple","title":"ExperienceStore (Legacy/Simple)","text":"<p>File: <code>store.py</code></p> <p>A simpler, flat storage system for experience records. Uses <code>MemoryConnector</code> to delegate to either the Kuzu or SQLite backend. Provides:</p> <ul> <li>Automatic compression of old experiences</li> <li>Retention policies (age limit, count limit)</li> <li>Duplicate detection</li> <li>Full-text search</li> <li>Storage quota enforcement</li> </ul>"},{"location":"architecture/#memoryconnector-backend-factory","title":"MemoryConnector (Backend Factory)","text":"<p>File: <code>connector.py</code></p> <p>Factory class that creates and manages the appropriate backend:</p> <pre><code># Kuzu backend (default)\nconnector = MemoryConnector(agent_name=\"my-agent\", backend=\"kuzu\")\n\n# SQLite fallback\nconnector = MemoryConnector(agent_name=\"my-agent\", backend=\"sqlite\")\n</code></pre> <p>Each agent gets isolated storage under <code>~/.amplihack/memory/&lt;agent_name&gt;/</code>.</p>"},{"location":"architecture/#shared-utilities","title":"Shared Utilities","text":""},{"location":"architecture/#similarity-similaritypy","title":"Similarity (<code>similarity.py</code>)","text":"<p>Deterministic text similarity without ML embeddings:</p> <ul> <li><code>compute_word_similarity(a, b)</code> -- Jaccard coefficient on tokenized words minus stop words</li> <li><code>compute_tag_similarity(a, b)</code> -- Jaccard coefficient on tag lists</li> <li><code>compute_similarity(node_a, node_b)</code> -- Weighted composite: 0.5 * word + 0.2 * tag + 0.3 * concept</li> <li><code>rerank_facts_by_query(facts, query)</code> -- Rerank retrieved facts by keyword relevance; boost temporal facts when query contains temporal cues</li> </ul>"},{"location":"architecture/#entity-extraction-entity_extractionpy","title":"Entity Extraction (<code>entity_extraction.py</code>)","text":"<p>Extracts proper nouns from text using regex heuristics:</p> <ul> <li>Handles apostrophe names (O'Brien), hyphenated names (Al-Hassan), multi-word names (Sarah Chen)</li> <li>Checks concept field first (more specific), then content</li> <li>Returns lowercase for consistent indexing</li> </ul>"},{"location":"architecture/#contradiction-detection-contradictionpy","title":"Contradiction Detection (<code>contradiction.py</code>)","text":"<p>Detects when two facts about the same concept contain conflicting numerical values:</p> <ul> <li>Requires overlapping concept words (at least one meaningful word in common)</li> <li>Extracts numbers from both facts</li> <li>Flags when facts have numbers unique to each (potential update/conflict)</li> </ul>"},{"location":"architecture/#memoryclassifier-hierarchical_memorypy","title":"MemoryClassifier (<code>hierarchical_memory.py</code>)","text":"<p>Rule-based keyword classifier:</p> Keywords Category step, how to, procedure, recipe PROCEDURAL plan, goal, future, will, todo PROSPECTIVE happened, event, observed EPISODIC (default) SEMANTIC"},{"location":"architecture/#security-layer-securitypy","title":"Security Layer (<code>security.py</code>)","text":"<ul> <li>AgentCapabilities -- Capability-based access control (scope levels, allowed types, query cost limits)</li> <li>CredentialScrubber -- Regex-based detection and redaction of API keys, passwords, tokens, SSH keys, DB URLs</li> <li>QueryValidator -- SQL query cost estimation and safety validation</li> <li>SecureMemoryBackend -- Wrapper that enforces all security policies</li> </ul>"},{"location":"architecture/#pattern-recognition-pattern_recognitionpy","title":"Pattern Recognition (<code>pattern_recognition.py</code>)","text":"<ul> <li>PatternDetector -- Tracks recurring patterns across discoveries, recognizes when threshold is reached</li> <li><code>recognize_patterns()</code> -- Batch pattern recognition with known-pattern filtering</li> <li>Confidence formula: <code>min(0.5 + occurrences * 0.1, 0.95)</code>, adjusted by validation success rate</li> </ul>"},{"location":"architecture/#design-philosophy","title":"Design Philosophy","text":""},{"location":"architecture/#ruthless-simplicity","title":"Ruthless Simplicity","text":"<p>Every component has a single, clear purpose. No unnecessary abstractions. The similarity module uses Jaccard coefficients instead of ML embeddings -- simple, deterministic, and sufficient for the use case.</p>"},{"location":"architecture/#zero-bs-implementation","title":"Zero-BS Implementation","text":"<p>No stubs, no placeholders, no fake implementations. Every function works or does not exist. The security layer actually scrubs credentials. The pattern detector actually tracks occurrences.</p>"},{"location":"architecture/#regeneratable-bricks-studs","title":"Regeneratable (Bricks &amp; Studs)","text":"<p>Each module is a self-contained \"brick\" with a well-defined public API (\"stud\"). The similarity module, entity extraction, and contradiction detection are all independent -- they can be replaced, tested, or regenerated from their specification without affecting other modules.</p>"},{"location":"architecture/#data-flow","title":"Data Flow","text":""},{"location":"architecture/#store-knowledge-flow","title":"Store Knowledge Flow","text":"<pre><code>User calls store_knowledge(content, concept, ...)\n    |\n    v\nMemoryClassifier assigns category (if not given)\n    |\n    v\nextract_entity_name() extracts proper nouns\n    |\n    v\nCREATE SemanticMemory node in Kuzu\n    |\n    +---&gt; If source_id: CREATE DERIVES_FROM edge\n    |\n    +---&gt; If temporal: _detect_supersedes()\n    |       |\n    |       +---&gt; Find existing facts for same entity\n    |       +---&gt; detect_contradiction() checks for conflicts\n    |       +---&gt; CREATE SUPERSEDES edge + TRANSITIONED_TO edge\n    |\n    +---&gt; _create_similarity_edges()\n            |\n            +---&gt; compute_similarity() against recent nodes\n            +---&gt; CREATE SIMILAR_TO edges for scores &gt; 0.3\n</code></pre>"},{"location":"architecture/#retrieve-subgraph-flow-graph-rag","title":"Retrieve Subgraph Flow (Graph RAG)","text":"<pre><code>User calls retrieve_subgraph(query, max_nodes=20)\n    |\n    v\nKeyword matching: CONTAINS on concept + content\n    |\n    v\nEntity-centric retrieval: extract_entity_name(query)\n    +---&gt; Match on entity_name field\n    |\n    v\nMerge direct matches (deduped by memory_id)\n    |\n    v\nGraph traversal: follow SIMILAR_TO edges (1 hop)\n    |\n    v\nFollow SUPERSEDES chain for temporal context\n    |\n    v\nFollow TRANSITIONED_TO chain for value transitions\n    |\n    v\nCollect all edges between result nodes\n    |\n    v\nReturn KnowledgeSubgraph(nodes, edges, query)\n    |\n    v\nUser calls subgraph.to_llm_context() for LLM-ready text\n</code></pre>"},{"location":"cognitive_memory/","title":"Cognitive Memory","text":"<p>The <code>CognitiveMemory</code> class provides a six-type memory system modeled after human cognition, where each memory type has distinct storage, lifecycle, and retrieval characteristics.</p>"},{"location":"cognitive_memory/#overview","title":"Overview","text":"<p>CognitiveMemory manages six separate Kuzu node tables -- one per memory type -- plus relationship edges that connect them:</p> <pre><code>                    ATTENDED_TO\n    SensoryMemory -----------------&gt; EpisodicMemory\n                                          |\n                                    DERIVES_FROM\n                                          |\n                                          v\n                                    SemanticMemory\n                                     |          |\n                               SIMILAR_TO   SIMILAR_TO\n                                     |          |\n                                     v          v\n                              SemanticMemory  SemanticMemory\n\n    ProceduralMemory  &lt;--- PROCEDURE_DERIVES_FROM --- EpisodicMemory\n\n    ConsolidatedEpisode --- CONSOLIDATES ---&gt; EpisodicMemory (compressed)\n\n    ProspectiveMemory (standalone, checked against content triggers)\n    WorkingMemory (standalone, bounded capacity per task)\n</code></pre>"},{"location":"cognitive_memory/#the-six-memory-types","title":"The Six Memory Types","text":""},{"location":"cognitive_memory/#1-sensory-memory","title":"1. Sensory Memory","text":"<p>Purpose: Short-lived raw observations that auto-expire.</p> <p>Characteristics:</p> <ul> <li>TTL-based expiration (default: 5 minutes)</li> <li>Monotonic observation ordering</li> <li>Can be promoted to episodic memory via \"attention\"</li> </ul> <pre><code>cog = CognitiveMemory(\"agent\", \"/tmp/cog_db\")\n\n# Record an observation\nsid = cog.record_sensory(\n    modality=\"error\",           # Channel: \"text\", \"code\", \"error\", \"log\"\n    raw_data=\"TypeError: expected str, got int\",\n    ttl_seconds=300,            # Expires in 5 minutes\n)\n\n# Get recent (non-expired) sensory items\nitems = cog.get_recent_sensory(limit=10)\n# Returns list of SensoryItem ordered by observation_order DESC\n\n# Promote to episodic memory (creates ATTENDED_TO edge)\nep_id = cog.attend_to_sensory(sid, reason=\"This error pattern keeps recurring\")\n\n# Clean up expired items\npruned = cog.prune_expired_sensory()\n</code></pre> <p>Dataclass: <code>SensoryItem</code></p> Field Type Description <code>node_id</code> <code>str</code> Unique graph identifier <code>modality</code> <code>str</code> Observation channel <code>raw_data</code> <code>str</code> Raw observation content <code>observation_order</code> <code>int</code> Monotonic insertion order <code>expires_at</code> <code>float</code> Unix timestamp for expiry <code>created_at</code> <code>datetime</code> Creation time"},{"location":"cognitive_memory/#2-working-memory","title":"2. Working Memory","text":"<p>Purpose: Active task context with bounded capacity.</p> <p>Characteristics:</p> <ul> <li>Fixed capacity of 20 slots per task</li> <li>Evicts lowest-relevance slot when full</li> <li>Scoped by <code>task_id</code></li> </ul> <pre><code># Push a slot (auto-evicts if at capacity)\nwid = cog.push_working(\n    slot_type=\"goal\",           # e.g., \"goal\", \"constraint\", \"context\"\n    content=\"Deploy v2.0 to staging by Friday\",\n    task_id=\"sprint-42\",\n    relevance=0.9,              # Priority weight (higher = more relevant)\n)\n\n# Get all working memory for a task\nslots = cog.get_working(\"sprint-42\")\n# Returns list of WorkingMemorySlot ordered by relevance DESC\n\n# Clear working memory when task is done\ncleared = cog.clear_working(\"sprint-42\")\n</code></pre> <p>Dataclass: <code>WorkingMemorySlot</code></p> Field Type Description <code>node_id</code> <code>str</code> Unique graph identifier <code>slot_type</code> <code>str</code> Categorisation of the slot <code>content</code> <code>str</code> Payload <code>relevance</code> <code>float</code> Priority weight (default 1.0) <code>task_id</code> <code>str</code> Associated task <code>created_at</code> <code>datetime</code> Creation time"},{"location":"cognitive_memory/#3-episodic-memory","title":"3. Episodic Memory","text":"<p>Purpose: Autobiographical event records that can be consolidated.</p> <p>Characteristics:</p> <ul> <li>Temporal ordering via monotonic index</li> <li>Consolidation compresses old episodes into summaries</li> <li>Compressed episodes are excluded from default queries</li> </ul> <pre><code># Store an episode\neid = cog.store_episode(\n    content=\"User requested API rate limiting feature\",\n    source_label=\"user-session\",\n    metadata={\"sprint\": 42},\n)\n\n# Retrieve episodes (excludes compressed by default)\nepisodes = cog.get_episodes(limit=20)\n\n# Include compressed episodes\nall_episodes = cog.get_episodes(limit=50, include_compressed=True)\n\n# Consolidate oldest episodes into a summary\ncons_id = cog.consolidate_episodes(\n    batch_size=10,\n    summarizer=lambda contents: \"Summary: \" + \"; \".join(contents),\n)\n# Returns ConsolidatedEpisode node_id, or None if fewer than batch_size available\n</code></pre> <p>Consolidation process:</p> <ol> <li>Fetch the <code>batch_size</code> oldest un-compressed episodes</li> <li>Apply the <code>summarizer</code> function (or simple concatenation if None)</li> <li>Create a <code>ConsolidatedEpisode</code> node with the summary</li> <li>Mark original episodes as <code>compressed=True</code></li> <li>Create <code>CONSOLIDATES</code> edges from the consolidated node to each original</li> </ol> <p>Dataclass: <code>EpisodicMemory</code></p> Field Type Description <code>node_id</code> <code>str</code> Unique graph identifier <code>content</code> <code>str</code> Episode description <code>source_label</code> <code>str</code> Origin label <code>temporal_index</code> <code>int</code> Monotonic ordering <code>compressed</code> <code>bool</code> Whether consolidated <code>created_at</code> <code>datetime</code> Creation time <code>metadata</code> <code>dict</code> Optional structured data"},{"location":"cognitive_memory/#4-semantic-memory","title":"4. Semantic Memory","text":"<p>Purpose: Distilled facts and knowledge, searchable by keyword.</p> <p>Characteristics:</p> <ul> <li>Keyword-based search (CONTAINS on concept + content)</li> <li>Confidence scoring</li> <li>Tags and metadata</li> <li>Source provenance tracking</li> </ul> <pre><code># Store a fact\nfid = cog.store_fact(\n    concept=\"rate-limiting\",\n    content=\"API rate limit is 1000 requests per minute\",\n    confidence=0.95,\n    source_id=\"ep_abc123\",     # Optional provenance\n    tags=[\"api\", \"config\"],\n    temporal_metadata={\"source_date\": \"2024-01-15\"},\n)\n\n# Search facts by keyword\nfacts = cog.search_facts(\"rate limit\", limit=10, min_confidence=0.5)\n\n# Get all facts\nall_facts = cog.get_all_facts(limit=50)\n</code></pre> <p>Dataclass: <code>SemanticFact</code></p> Field Type Description <code>node_id</code> <code>str</code> Unique graph identifier <code>concept</code> <code>str</code> Topic/concept <code>content</code> <code>str</code> Factual content <code>confidence</code> <code>float</code> Confidence (0.0-1.0) <code>source_id</code> <code>str</code> Provenance reference <code>tags</code> <code>list[str]</code> Categorisation tags <code>metadata</code> <code>dict</code> Additional metadata <code>created_at</code> <code>datetime</code> Creation time"},{"location":"cognitive_memory/#5-procedural-memory","title":"5. Procedural Memory","text":"<p>Purpose: Reusable step-by-step procedures with usage tracking.</p> <p>Characteristics:</p> <ul> <li>Ordered step lists</li> <li>Prerequisites tracking</li> <li>Usage count auto-incremented on recall</li> <li>Keyword search on name and steps</li> </ul> <pre><code># Store a procedure\npid = cog.store_procedure(\n    name=\"Deploy to production\",\n    steps=[\"Run test suite\", \"Build Docker image\", \"Push to registry\", \"Update k8s manifests\"],\n    prerequisites=[\"All tests passing\", \"Approval from tech lead\"],\n)\n\n# Recall procedures (auto-increments usage_count)\nprocs = cog.recall_procedure(\"deploy production\", limit=5)\nfor proc in procs:\n    print(f\"{proc.name}: {proc.steps} (used {proc.usage_count} times)\")\n</code></pre> <p>Dataclass: <code>ProceduralMemory</code></p> Field Type Description <code>node_id</code> <code>str</code> Unique graph identifier <code>name</code> <code>str</code> Procedure name <code>steps</code> <code>list[str]</code> Ordered step list <code>prerequisites</code> <code>list[str]</code> Required conditions <code>usage_count</code> <code>int</code> Times recalled <code>created_at</code> <code>datetime</code> Creation time"},{"location":"cognitive_memory/#6-prospective-memory","title":"6. Prospective Memory","text":"<p>Purpose: Future-oriented trigger-action pairs.</p> <p>Characteristics:</p> <ul> <li>Three states: <code>pending</code> -&gt; <code>triggered</code> -&gt; <code>resolved</code></li> <li>Priority-based ordering</li> <li>Keyword-overlap trigger matching</li> </ul> <pre><code># Store a trigger-action pair\npid = cog.store_prospective(\n    description=\"Alert on deployment failure\",\n    trigger_condition=\"deployment failed error\",\n    action_on_trigger=\"Send alert to #ops-channel and rollback\",\n    priority=3,\n)\n\n# Check triggers against new content\ntriggered = cog.check_triggers(\"The deployment failed with timeout error\")\nfor pm in triggered:\n    print(f\"TRIGGERED: {pm.description} -&gt; {pm.action_on_trigger}\")\n\n# Mark as resolved after handling\ncog.resolve_prospective(triggered[0].node_id)\n</code></pre> <p>Trigger matching: Simple keyword overlap -- if any word from <code>trigger_condition</code> appears in the content, the prospective memory is triggered.</p> <p>Dataclass: <code>ProspectiveMemory</code></p> Field Type Description <code>node_id</code> <code>str</code> Unique graph identifier <code>description</code> <code>str</code> Description <code>trigger_condition</code> <code>str</code> Trigger text <code>action_on_trigger</code> <code>str</code> Action to take <code>status</code> <code>str</code> pending/triggered/resolved <code>priority</code> <code>int</code> Priority level <code>created_at</code> <code>datetime</code> Creation time"},{"location":"cognitive_memory/#statistics","title":"Statistics","text":"<pre><code>stats = cog.get_statistics()\n# {\n#     \"sensory\": 5,\n#     \"working\": 12,\n#     \"episodic\": 45,\n#     \"semantic\": 120,\n#     \"procedural\": 8,\n#     \"prospective\": 3,\n#     \"total\": 193,\n# }\n</code></pre>"},{"location":"cognitive_memory/#lifecycle","title":"Lifecycle","text":"<pre><code># Create\ncog = CognitiveMemory(\"my-agent\", \"/tmp/cog_db\")\n\n# Use...\n\n# Close (releases Kuzu connection)\ncog.close()\n</code></pre> <p>The <code>CognitiveMemory</code> instance manages a single Kuzu database connection. Call <code>close()</code> when done to release resources. Agent isolation is achieved via the <code>agent_id</code> column on every node table.</p>"},{"location":"extending/","title":"Extending amplihack-memory-lib","text":"<p>This guide covers how to extend the library with custom backends, new edge types, custom classifiers, and integration patterns.</p>"},{"location":"extending/#custom-memory-backends","title":"Custom Memory Backends","text":""},{"location":"extending/#implementing-the-memorybackend-interface","title":"Implementing the MemoryBackend Interface","text":"<p>All backends must implement the abstract <code>MemoryBackend</code> class:</p> <pre><code>from amplihack_memory.backends.base import MemoryBackend\nfrom amplihack_memory.experience import Experience, ExperienceType\n\n\nclass MyCustomBackend(MemoryBackend):\n    \"\"\"Custom backend implementation.\"\"\"\n\n    def __init__(self, db_path, agent_name, max_memory_mb=100, enable_compression=True):\n        self.db_path = db_path\n        self.agent_name = agent_name\n        self.max_memory_mb = max_memory_mb\n        self.enable_compression = enable_compression\n        self.initialize_schema()\n\n    def initialize_schema(self):\n        \"\"\"Create storage schema.\"\"\"\n        # Set up your storage (tables, files, etc.)\n        ...\n\n    def store_experience(self, experience: Experience) -&gt; str:\n        \"\"\"Store an experience. Returns experience_id.\"\"\"\n        ...\n\n    def retrieve_experiences(self, limit=None, experience_type=None, min_confidence=0.0):\n        \"\"\"Retrieve experiences sorted by recency.\"\"\"\n        ...\n\n    def search(self, query, experience_type=None, min_confidence=0.0, limit=10):\n        \"\"\"Search by text query.\"\"\"\n        ...\n\n    def get_statistics(self) -&gt; dict:\n        \"\"\"Return storage statistics.\"\"\"\n        ...\n\n    def close(self):\n        \"\"\"Release resources.\"\"\"\n        ...\n\n    def get_connection(self):\n        \"\"\"Return underlying connection object.\"\"\"\n        ...\n\n    def cleanup(self, auto_compress=True, max_age_days=None, max_experiences=None):\n        \"\"\"Run cleanup operations.\"\"\"\n        ...\n</code></pre>"},{"location":"extending/#registering-a-custom-backend","title":"Registering a Custom Backend","text":"<p>To use your backend with <code>MemoryConnector</code>, modify the factory logic:</p> <pre><code>from amplihack_memory.connector import MemoryConnector\n\n\n# Option 1: Direct backend injection\nfrom amplihack_memory.backends.base import MemoryBackend\n\nclass MyConnector(MemoryConnector):\n    def __init__(self, agent_name, backend=\"custom\", **kwargs):\n        if backend == \"custom\":\n            self._backend = MyCustomBackend(\n                db_path=kwargs.get(\"storage_path\", \"default_path\"),\n                agent_name=agent_name,\n            )\n        else:\n            super().__init__(agent_name, backend=backend, **kwargs)\n</code></pre> <pre><code># Option 2: Use the backend directly with ExperienceStore pattern\nfrom amplihack_memory.store import ExperienceStore\n\n\nclass CustomExperienceStore:\n    \"\"\"ExperienceStore with custom backend.\"\"\"\n\n    def __init__(self, agent_name, backend_instance):\n        self.agent_name = agent_name\n        self._backend = backend_instance\n\n    def add(self, experience):\n        return self._backend.store_experience(experience)\n\n    def search(self, query, **kwargs):\n        return self._backend.search(query, **kwargs)\n</code></pre>"},{"location":"extending/#new-edge-types","title":"New Edge Types","text":""},{"location":"extending/#adding-edges-to-hierarchicalmemory","title":"Adding Edges to HierarchicalMemory","text":"<p>To add a new relationship type to the knowledge graph:</p> <p>Step 1: Add the schema definition in <code>_init_schema()</code>:</p> <pre><code># In hierarchical_memory.py, inside _init_schema()\nself.connection.execute(\"\"\"\n    CREATE REL TABLE IF NOT EXISTS CAUSED_BY(\n        FROM SemanticMemory TO SemanticMemory,\n        cause_type STRING,\n        confidence DOUBLE\n    )\n\"\"\")\n</code></pre> <p>Step 2: Add a method to create the edge:</p> <pre><code>def _create_causal_edge(self, effect_id: str, cause_id: str, cause_type: str, confidence: float):\n    \"\"\"Create a CAUSED_BY edge between two knowledge nodes.\"\"\"\n    try:\n        self.connection.execute(\n            \"\"\"\n            MATCH (effect:SemanticMemory), (cause:SemanticMemory)\n            WHERE effect.memory_id = $eid AND cause.memory_id = $cid\n            CREATE (effect)-[:CAUSED_BY {\n                cause_type: $ct,\n                confidence: $conf\n            }]-&gt;(cause)\n            \"\"\",\n            {\"eid\": effect_id, \"cid\": cause_id, \"ct\": cause_type, \"conf\": confidence},\n        )\n    except Exception as e:\n        logger.warning(\"Failed to create CAUSED_BY edge: %s\", e)\n</code></pre> <p>Step 3: Include the edge in retrieval:</p> <pre><code># In retrieve_subgraph(), add traversal for the new edge type\n# after the similarity traversal section:\n\ncausal_result = self.connection.execute(\n    \"\"\"\n    MATCH (a:SemanticMemory)-[e:CAUSED_BY]-(b:SemanticMemory)\n    WHERE a.memory_id IN $ids AND b.agent_id = $agent_id\n    RETURN b.memory_id, b.concept, b.content, b.confidence, ...\n    \"\"\",\n    {\"ids\": list(seen_ids), \"agent_id\": self.agent_name},\n)\n</code></pre>"},{"location":"extending/#adding-edges-to-cognitivememory","title":"Adding Edges to CognitiveMemory","text":"<p>For CognitiveMemory, add the table to the <code>_REL_TABLES</code> list:</p> <pre><code># In cognitive_memory.py, add to _REL_TABLES list:\n_REL_TABLES = [\n    # ... existing tables ...\n    \"\"\"\n    CREATE REL TABLE IF NOT EXISTS CAUSED_BY(\n        FROM SemanticMemory TO SemanticMemory,\n        cause_type STRING,\n        confidence DOUBLE\n    )\n    \"\"\",\n]\n</code></pre>"},{"location":"extending/#custom-classifiers","title":"Custom Classifiers","text":""},{"location":"extending/#replacing-the-memoryclassifier","title":"Replacing the MemoryClassifier","text":"<p>The default <code>MemoryClassifier</code> uses keyword matching. To create a more sophisticated classifier:</p> <pre><code>from amplihack_memory.hierarchical_memory import MemoryCategory\n\n\nclass LLMClassifier:\n    \"\"\"Memory classifier using an LLM for nuanced categorization.\"\"\"\n\n    def __init__(self, llm_client):\n        self.llm = llm_client\n\n    def classify(self, content: str, concept: str = \"\") -&gt; MemoryCategory:\n        \"\"\"Classify using LLM.\"\"\"\n        prompt = f\"\"\"Classify this memory into one category:\n        - episodic: Events that happened\n        - semantic: Factual knowledge\n        - procedural: Step-by-step procedures\n        - prospective: Future plans or intentions\n        - working: Active task context\n\n        Content: {content}\n        Concept: {concept}\n\n        Category:\"\"\"\n\n        result = self.llm.complete(prompt).strip().lower()\n\n        try:\n            return MemoryCategory(result)\n        except ValueError:\n            return MemoryCategory.SEMANTIC  # Safe default\n</code></pre> <p>To use it, inject it into the HierarchicalMemory instance:</p> <pre><code>mem = HierarchicalMemory(\"my-agent\", \"/tmp/mem_db\")\nmem._classifier = LLMClassifier(my_llm_client)\n</code></pre>"},{"location":"extending/#custom-similarity-functions","title":"Custom Similarity Functions","text":"<p>Replace the default Jaccard similarity with embeddings:</p> <pre><code>from amplihack_memory.similarity import compute_similarity\n\n\ndef embedding_similarity(node_a: dict, node_b: dict) -&gt; float:\n    \"\"\"Compute similarity using vector embeddings.\"\"\"\n    vec_a = embed(node_a.get(\"content\", \"\"))\n    vec_b = embed(node_b.get(\"content\", \"\"))\n    return cosine_similarity(vec_a, vec_b)\n\n\n# Monkey-patch or subclass HierarchicalMemory to use your function\n# in _create_similarity_edges()\n</code></pre>"},{"location":"extending/#integration-patterns","title":"Integration Patterns","text":""},{"location":"extending/#using-with-langchain","title":"Using with LangChain","text":"<pre><code>from amplihack_memory import HierarchicalMemory\n\n\nclass AmplihackMemoryRetriever:\n    \"\"\"LangChain-compatible retriever backed by HierarchicalMemory.\"\"\"\n\n    def __init__(self, agent_name: str, db_path: str):\n        self.mem = HierarchicalMemory(agent_name, db_path)\n\n    def get_relevant_documents(self, query: str) -&gt; list[dict]:\n        \"\"\"Retrieve relevant documents for a query.\"\"\"\n        subgraph = self.mem.retrieve_subgraph(query, max_nodes=10)\n        return [\n            {\n                \"page_content\": node.content,\n                \"metadata\": {\n                    \"concept\": node.concept,\n                    \"confidence\": node.confidence,\n                    \"source_id\": node.source_id,\n                    \"tags\": node.tags,\n                },\n            }\n            for node in subgraph.nodes\n        ]\n</code></pre>"},{"location":"extending/#using-with-claudeanthropic-agents","title":"Using with Claude/Anthropic Agents","text":"<pre><code>from amplihack_memory import HierarchicalMemory\n\n\nclass AgentMemory:\n    \"\"\"Memory adapter for Claude-based agents.\"\"\"\n\n    def __init__(self, agent_name: str):\n        self.mem = HierarchicalMemory(agent_name)\n\n    def remember(self, content: str, concept: str = \"\", **kwargs):\n        \"\"\"Store knowledge from agent interactions.\"\"\"\n        return self.mem.store_knowledge(content, concept, **kwargs)\n\n    def recall(self, query: str) -&gt; str:\n        \"\"\"Retrieve knowledge as LLM context.\"\"\"\n        subgraph = self.mem.retrieve_subgraph(query)\n        return subgraph.to_llm_context()\n\n    def learn_from_episode(self, raw_content: str, source: str, facts: list[dict]):\n        \"\"\"Store an episode and derived facts with provenance.\"\"\"\n        ep_id = self.mem.store_episode(raw_content, source_label=source)\n        for fact in facts:\n            self.mem.store_knowledge(\n                content=fact[\"content\"],\n                concept=fact.get(\"concept\", \"\"),\n                source_id=ep_id,\n                tags=fact.get(\"tags\", []),\n            )\n</code></pre>"},{"location":"extending/#using-with-multi-agent-systems","title":"Using with Multi-Agent Systems","text":"<pre><code>from amplihack_memory import HierarchicalMemory\n\n\n# Each agent gets its own isolated memory\narchitect_mem = HierarchicalMemory(\"architect-agent\")\nbuilder_mem = HierarchicalMemory(\"builder-agent\")\nreviewer_mem = HierarchicalMemory(\"reviewer-agent\")\n\n# Share knowledge between agents via export/import\nshared_knowledge = architect_mem.export_graph()\nbuilder_mem.import_graph(shared_knowledge)\n</code></pre>"},{"location":"extending/#session-scoped-memory-with-cognitivememory","title":"Session-Scoped Memory with CognitiveMemory","text":"<pre><code>from amplihack_memory import CognitiveMemory\n\n\nclass SessionMemory:\n    \"\"\"Session-scoped memory using all six cognitive types.\"\"\"\n\n    def __init__(self, agent_name: str, session_id: str):\n        self.cog = CognitiveMemory(agent_name, f\"/tmp/session_{session_id}\")\n        self.session_id = session_id\n\n    def observe(self, data: str, modality: str = \"text\"):\n        \"\"\"Record a sensory observation.\"\"\"\n        return self.cog.record_sensory(modality, data)\n\n    def focus(self, goal: str, context: str):\n        \"\"\"Push items into working memory for the current task.\"\"\"\n        self.cog.push_working(\"goal\", goal, task_id=self.session_id)\n        self.cog.push_working(\"context\", context, task_id=self.session_id)\n\n    def note(self, event: str, source: str = \"\"):\n        \"\"\"Record an event.\"\"\"\n        return self.cog.store_episode(event, source_label=source or self.session_id)\n\n    def learn(self, concept: str, fact: str, confidence: float = 0.9):\n        \"\"\"Store a learned fact.\"\"\"\n        return self.cog.store_fact(concept, fact, confidence=confidence)\n\n    def remind_me(self, trigger: str, action: str):\n        \"\"\"Set a reminder for future conditions.\"\"\"\n        return self.cog.store_prospective(\n            f\"Reminder for {self.session_id}\",\n            trigger_condition=trigger,\n            action_on_trigger=action,\n        )\n\n    def check_reminders(self, current_state: str):\n        \"\"\"Check if any reminders should fire.\"\"\"\n        return self.cog.check_triggers(current_state)\n\n    def cleanup(self):\n        \"\"\"Prune expired sensory data and consolidate old episodes.\"\"\"\n        self.cog.prune_expired_sensory()\n        self.cog.consolidate_episodes(batch_size=10)\n\n    def close(self):\n        self.cog.close()\n</code></pre>"},{"location":"extending/#best-practices","title":"Best Practices","text":"<ol> <li> <p>One agent, one memory instance -- Do not share HierarchicalMemory or CognitiveMemory instances across threads. Create separate instances if needed.</p> </li> <li> <p>Close when done -- Always call <code>close()</code> or use context managers to release Kuzu connections.</p> </li> <li> <p>Use concepts consistently -- Consistent concept labels improve similarity edge quality and retrieval accuracy.</p> </li> <li> <p>Tag strategically -- Tags contribute to similarity scores (20% weight). Use consistent, meaningful tags.</p> </li> <li> <p>Provide source_id for provenance -- Store episodes first, then derive facts with <code>source_id</code> pointing to the episode. This creates a traceable knowledge lineage.</p> </li> <li> <p>Use temporal_metadata for evolving knowledge -- When facts change over time, provide <code>temporal_metadata</code> with <code>temporal_index</code> to enable automatic SUPERSEDES detection.</p> </li> </ol>"},{"location":"hierarchical_memory/","title":"Hierarchical Memory","text":"<p>The <code>HierarchicalMemory</code> class is the primary memory system for AI agents that need structured, graph-based knowledge storage with relationship tracking and Graph RAG retrieval.</p>"},{"location":"hierarchical_memory/#overview","title":"Overview","text":"<p>HierarchicalMemory manages a Kuzu knowledge graph with two node types and four edge types:</p> <p>Node Types:</p> <ul> <li>SemanticMemory -- Distilled facts (concept, content, confidence, tags, entity_name)</li> <li>EpisodicMemory -- Raw source content with provenance labels</li> </ul> <p>Edge Types:</p> <ul> <li>SIMILAR_TO -- Text similarity between semantic nodes (auto-computed on store)</li> <li>DERIVES_FROM -- Provenance link from fact to source episode</li> <li>SUPERSEDES -- Temporal update (newer fact replaces older about same entity)</li> <li>TRANSITIONED_TO -- Explicit value transition chain for temporal reasoning</li> </ul>"},{"location":"hierarchical_memory/#memory-categories","title":"Memory Categories","text":"<p>HierarchicalMemory uses five categories from the <code>MemoryCategory</code> enum:</p> Category Value Description Classification Keywords EPISODIC <code>\"episodic\"</code> Events that happened happened, event, observed SEMANTIC <code>\"semantic\"</code> Factual knowledge (default) (anything not matching other categories) PROCEDURAL <code>\"procedural\"</code> Step-by-step procedures step, how to, procedure, recipe PROSPECTIVE <code>\"prospective\"</code> Future plans/intentions plan, goal, future, will, todo WORKING <code>\"working\"</code> Active task context (not auto-classified; set explicitly) <p>The <code>MemoryClassifier</code> auto-assigns categories based on keyword matching. You can override by passing <code>category=</code> explicitly.</p>"},{"location":"hierarchical_memory/#storing-knowledge","title":"Storing Knowledge","text":""},{"location":"hierarchical_memory/#basic-storage","title":"Basic Storage","text":"<pre><code>from amplihack_memory import HierarchicalMemory, MemoryCategory\n\nmem = HierarchicalMemory(\"my-agent\", \"/tmp/mem_db\")\n\n# Auto-classified as SEMANTIC (default)\nnid = mem.store_knowledge(\n    content=\"Python was created by Guido van Rossum\",\n    concept=\"python-history\",\n    confidence=0.95,\n    tags=[\"python\", \"history\"],\n)\n\n# Explicitly set category\nnid = mem.store_knowledge(\n    content=\"Step 1: Clone repo. Step 2: Run tests. Step 3: Deploy.\",\n    concept=\"deployment-procedure\",\n    category=MemoryCategory.PROCEDURAL,\n)\n</code></pre>"},{"location":"hierarchical_memory/#what-happens-on-store","title":"What Happens on Store","text":"<ol> <li>Auto-classification -- If no category given, <code>MemoryClassifier</code> assigns one based on keywords</li> <li>Entity extraction -- <code>extract_entity_name()</code> finds proper nouns for entity-centric indexing</li> <li>Node creation -- SemanticMemory node created in Kuzu with all fields</li> <li>Provenance -- If <code>source_id</code> points to an existing EpisodicMemory node, a <code>DERIVES_FROM</code> edge is created</li> <li>Temporal updates -- If <code>temporal_metadata</code> with <code>temporal_index &gt; 0</code> is provided, the system checks for existing facts about the same entity and creates <code>SUPERSEDES</code> + <code>TRANSITIONED_TO</code> edges if a contradiction is detected</li> <li>Similarity edges -- <code>compute_similarity()</code> runs against recent nodes; <code>SIMILAR_TO</code> edges are created for scores above 0.3</li> </ol>"},{"location":"hierarchical_memory/#storing-episodes","title":"Storing Episodes","text":"<p>Episodes are raw source content -- the provenance from which facts are derived:</p> <pre><code>episode_id = mem.store_episode(\n    content=\"In the 2024 Olympics, Norway won 15 gold medals...\",\n    source_label=\"news-article-2024\",\n)\n\n# Later, store a fact derived from this episode\nfact_id = mem.store_knowledge(\n    content=\"Norway won 15 gold medals in 2024 Olympics\",\n    concept=\"norway-olympics\",\n    source_id=episode_id,  # Creates DERIVES_FROM edge\n)\n</code></pre>"},{"location":"hierarchical_memory/#supersedes-edges-temporal-updates","title":"SUPERSEDES Edges (Temporal Updates)","text":"<p>When knowledge evolves over time, SUPERSEDES edges track updates:</p> <pre><code># Day 1: Initial fact\nmem.store_knowledge(\n    content=\"Klaebo has 9 gold medals\",\n    concept=\"Klaebo medals\",\n    temporal_metadata={\"temporal_index\": 1, \"source_date\": \"Day 1\"},\n)\n\n# Day 2: Updated fact (auto-detected via contradiction)\nmem.store_knowledge(\n    content=\"Klaebo has 10 gold medals\",\n    concept=\"Klaebo medals\",\n    temporal_metadata={\"temporal_index\": 2, \"source_date\": \"Day 2\"},\n)\n# Result: (Day 2 fact)-[:SUPERSEDES]-&gt;(Day 1 fact)\n</code></pre> <p>How supersession works:</p> <ol> <li>When a new fact has <code>temporal_index &gt; 0</code>, the system searches for existing facts about the same entity</li> <li><code>detect_contradiction()</code> checks if the facts share concept words but have different numbers</li> <li>If contradiction detected: the new fact SUPERSEDES the old one, and the old fact's confidence is reduced</li> <li>A <code>TRANSITIONED_TO</code> edge is also created to enable multi-hop traversal of the value history</li> </ol>"},{"location":"hierarchical_memory/#transitioned_to-edges-value-chains","title":"TRANSITIONED_TO Edges (Value Chains)","text":"<p>TRANSITIONED_TO edges create explicit value transition chains:</p> <pre><code>(latest: \"10 golds\")-[:TRANSITIONED_TO]-&gt;(intermediate: \"9 golds\")\n                                              |\n                                    [:TRANSITIONED_TO]\n                                              |\n                                              v\n                                    (first: \"8 golds\")\n</code></pre> <p>These edges store:</p> Field Description <code>from_value</code> The newer value <code>to_value</code> The older value <code>turn</code> The temporal index of the newer fact <code>transition_type</code> Type of transition (e.g., <code>\"update\"</code>) <p>The <code>to_llm_context(chronological=True)</code> method uses these edges to present a chronological history to the LLM.</p>"},{"location":"hierarchical_memory/#similarity-based-graph-rag","title":"Similarity-Based Graph RAG","text":""},{"location":"hierarchical_memory/#how-similarity-works","title":"How Similarity Works","text":"<p>On every <code>store_knowledge()</code> call, the system:</p> <ol> <li>Fetches the 50 most recent SemanticMemory nodes for the same agent</li> <li>Computes <code>compute_similarity()</code> between the new node and each existing node</li> <li>Creates <code>SIMILAR_TO</code> edges for pairs with similarity &gt; 0.3</li> </ol> <p>The similarity score is a weighted composite:</p> <pre><code>score = 0.5 * word_similarity + 0.2 * tag_similarity + 0.3 * concept_similarity\n</code></pre> <p>Where each component uses Jaccard coefficients on tokenized text (lowercase, stop words removed).</p>"},{"location":"hierarchical_memory/#retrieve-subgraph","title":"Retrieve Subgraph","text":"<pre><code>subgraph = mem.retrieve_subgraph(\n    query=\"python type features\",\n    max_nodes=20,\n    similarity_threshold=0.3,\n)\n\n# Get LLM-ready context\ncontext = subgraph.to_llm_context()\nprint(context)\n</code></pre> <p>Retrieval process:</p> <ol> <li>Keyword matching -- <code>CONTAINS</code> on concept and content fields (case-insensitive)</li> <li>Entity-centric retrieval -- Extract entity name from query, match on <code>entity_name</code> field</li> <li>Merge and deduplicate -- Combine results by <code>memory_id</code></li> <li>Graph traversal -- Follow SIMILAR_TO edges (1 hop) from matched nodes</li> <li>Temporal context -- Follow SUPERSEDES and TRANSITIONED_TO chains</li> <li>Edge collection -- Gather all edges between result nodes</li> <li>Return -- <code>KnowledgeSubgraph(nodes, edges, query)</code></li> </ol>"},{"location":"hierarchical_memory/#llm-context-formatting","title":"LLM Context Formatting","text":"<pre><code># Default: sorted by confidence\ncontext = subgraph.to_llm_context()\n\n# Chronological: sorted by temporal_index\ncontext = subgraph.to_llm_context(chronological=True)\n</code></pre> <p>The formatted output includes:</p> <ul> <li>Numbered facts with concept labels and confidence scores</li> <li>Source provenance markers <code>[Source: ...]</code></li> <li>Chain position markers <code>[chain_position]</code></li> <li>Transition history (from TRANSITIONED_TO edges)</li> <li>Contradiction warnings (from edges with contradiction metadata)</li> <li>Relationship summary (SIMILAR_TO, DERIVES_FROM, etc.)</li> </ul>"},{"location":"hierarchical_memory/#entity-centric-retrieval","title":"Entity-Centric Retrieval","text":"<p>Entity names are extracted from content and concept fields using regex heuristics:</p> <pre><code>from amplihack_memory import extract_entity_name\n\nname = extract_entity_name(\"Klaebo won 10 gold medals\", \"Klaebo medals\")\n# Returns: \"klaebo\"\n</code></pre> <p>During retrieval, the system:</p> <ol> <li>Extracts entity name from the query</li> <li>Matches against the <code>entity_name</code> field on SemanticMemory nodes</li> <li>Merges with keyword-based results</li> </ol> <p>This enables questions like \"How many medals does Klaebo have?\" to find all facts about Klaebo, even if the exact wording differs.</p>"},{"location":"hierarchical_memory/#export-import","title":"Export / Import","text":"<pre><code># Export the full graph to a dict\ndata = mem.export_graph()\n# Returns: {\"nodes\": [...], \"edges\": [...], \"agent_name\": \"...\", \"exported_at\": \"...\"}\n\n# Import into a different memory instance\nother_mem = HierarchicalMemory(\"other-agent\", \"/tmp/other_db\")\nother_mem.import_graph(data)\n</code></pre>"},{"location":"hierarchical_memory/#protocol-compatible-aliases","title":"Protocol-Compatible Aliases","text":"<p>For interop with code that expects the <code>ExperienceStore</code> interface:</p> Alias Delegates To <code>store_fact(content, concept, confidence, **kwargs)</code> <code>store_knowledge()</code> <code>search_facts(query, max_nodes, **kwargs)</code> <code>retrieve_subgraph()</code> -- returns list of dicts <code>get_all_facts(limit)</code> <code>get_all_knowledge()</code> -- returns list of dicts <pre><code># These are equivalent:\nmem.store_knowledge(\"Python is great\", \"python\")\nmem.store_fact(\"Python is great\", \"python\")\n\n# search_facts returns dicts instead of KnowledgeSubgraph\nfacts = mem.search_facts(\"python\")\n# [{\"content\": \"Python is great\", \"concept\": \"python\", \"confidence\": 0.8, ...}]\n</code></pre>"},{"location":"hierarchical_memory/#static-utility-methods","title":"Static Utility Methods","text":"<pre><code># Get recent discoveries from memory\ndiscoveries = HierarchicalMemory.get_recent_discoveries(db_path, agent_name)\n\n# Store a discovery\nHierarchicalMemory.store_discovery(db_path, agent_name, discovery_dict)\n</code></pre> <p>These static methods provide backward-compatible access without requiring a full HierarchicalMemory instance.</p>"},{"location":"kuzu_backend/","title":"Kuzu Backend","text":"<p>amplihack-memory-lib uses Kuzu as its primary graph database backend. Kuzu is an embedded graph database (like SQLite for graphs) that requires no server -- it runs in-process and stores data in a local directory.</p>"},{"location":"kuzu_backend/#why-kuzu","title":"Why Kuzu","text":"Feature Benefit Embedded No server setup, runs in-process Graph-native First-class support for nodes, edges, and graph traversal Cypher-compatible Uses openCypher query language Persistent Stores data on disk, survives process restarts Fast Columnar storage with vectorized execution Python bindings Native Python API via <code>kuzu</code> package"},{"location":"kuzu_backend/#database-layout","title":"Database Layout","text":"<p>Each memory system creates a Kuzu database directory:</p> <pre><code>~/.amplihack/\n    hierarchical_memory/\n        my-agent/           # HierarchicalMemory db\n            kuzu_db/        # Kuzu data directory\n    memory/\n        my-agent/           # MemoryConnector db\n            kuzu_db/        # Kuzu data directory\n</code></pre> <p>CognitiveMemory also creates a Kuzu database at the specified path:</p> <pre><code>/path/to/cognitive_db/      # CognitiveMemory db (user-specified)\n</code></pre>"},{"location":"kuzu_backend/#schema-hierarchicalmemory","title":"Schema: HierarchicalMemory","text":""},{"location":"kuzu_backend/#node-tables","title":"Node Tables","text":"<p>SemanticMemory -- Distilled facts:</p> <pre><code>CREATE NODE TABLE SemanticMemory(\n    memory_id STRING,        -- UUID primary key\n    concept STRING,          -- Topic/concept label\n    content STRING,          -- Factual content\n    confidence DOUBLE,       -- 0.0-1.0\n    source_id STRING,        -- Provenance (episode ID)\n    agent_id STRING,         -- Agent isolation\n    tags STRING,             -- JSON array of tags\n    metadata STRING,         -- JSON object\n    created_at STRING,       -- ISO timestamp\n    entity_name STRING,      -- Extracted entity (lowercase)\n    PRIMARY KEY (memory_id)\n)\n</code></pre> <p>EpisodicMemory -- Raw source content:</p> <pre><code>CREATE NODE TABLE EpisodicMemory(\n    memory_id STRING,        -- UUID primary key\n    content STRING,          -- Episode content\n    source_label STRING,     -- Origin label\n    agent_id STRING,         -- Agent isolation\n    tags STRING,             -- JSON array\n    metadata STRING,         -- JSON object\n    created_at STRING,       -- ISO timestamp\n    PRIMARY KEY (memory_id)\n)\n</code></pre>"},{"location":"kuzu_backend/#relationship-tables","title":"Relationship Tables","text":"<pre><code>-- Text similarity between facts\nCREATE REL TABLE SIMILAR_TO(\n    FROM SemanticMemory TO SemanticMemory,\n    weight DOUBLE,           -- Similarity score\n    metadata STRING          -- JSON (contradiction info)\n)\n\n-- Fact derived from episode (provenance)\nCREATE REL TABLE DERIVES_FROM(\n    FROM SemanticMemory TO EpisodicMemory,\n    extraction_method STRING,\n    confidence DOUBLE\n)\n\n-- Newer fact supersedes older (temporal update)\nCREATE REL TABLE SUPERSEDES(\n    FROM SemanticMemory TO SemanticMemory,\n    reason STRING,           -- Why it supersedes\n    temporal_delta STRING    -- Time difference description\n)\n\n-- Explicit value transition chain\nCREATE REL TABLE TRANSITIONED_TO(\n    FROM SemanticMemory TO SemanticMemory,\n    from_value STRING,       -- Newer value\n    to_value STRING,         -- Older value\n    turn INT64,              -- Temporal index\n    transition_type STRING   -- e.g., \"update\"\n)\n</code></pre>"},{"location":"kuzu_backend/#schema-cognitivememory","title":"Schema: CognitiveMemory","text":""},{"location":"kuzu_backend/#node-tables_1","title":"Node Tables","text":"<pre><code>CREATE NODE TABLE SensoryMemory(\n    node_id STRING, agent_id STRING,\n    modality STRING, raw_data STRING,\n    observation_order INT64, expires_at INT64, created_at INT64,\n    PRIMARY KEY(node_id)\n)\n\nCREATE NODE TABLE WorkingMemory(\n    node_id STRING, agent_id STRING,\n    slot_type STRING, content STRING,\n    relevance DOUBLE, task_id STRING, created_at INT64,\n    PRIMARY KEY(node_id)\n)\n\nCREATE NODE TABLE EpisodicMemory(\n    node_id STRING, agent_id STRING,\n    content STRING, source_label STRING,\n    temporal_index INT64, compressed BOOLEAN,\n    metadata STRING, created_at INT64,\n    PRIMARY KEY(node_id)\n)\n\nCREATE NODE TABLE SemanticMemory(\n    node_id STRING, agent_id STRING,\n    concept STRING, content STRING,\n    confidence DOUBLE, source_id STRING,\n    tags STRING, metadata STRING, created_at INT64,\n    PRIMARY KEY(node_id)\n)\n\nCREATE NODE TABLE ProceduralMemory(\n    node_id STRING, agent_id STRING,\n    name STRING, steps STRING,\n    prerequisites STRING, usage_count INT64, created_at INT64,\n    PRIMARY KEY(node_id)\n)\n\nCREATE NODE TABLE ProspectiveMemory(\n    node_id STRING, agent_id STRING,\n    desc_text STRING, trigger_condition STRING,\n    action_on_trigger STRING, status STRING,\n    priority INT64, created_at INT64,\n    PRIMARY KEY(node_id)\n)\n\nCREATE NODE TABLE ConsolidatedEpisode(\n    node_id STRING, agent_id STRING,\n    summary STRING, original_count INT64, created_at INT64,\n    PRIMARY KEY(node_id)\n)\n</code></pre>"},{"location":"kuzu_backend/#relationship-tables_1","title":"Relationship Tables","text":"<pre><code>CREATE REL TABLE SIMILAR_TO(FROM SemanticMemory TO SemanticMemory, similarity_score DOUBLE)\nCREATE REL TABLE DERIVES_FROM(FROM SemanticMemory TO EpisodicMemory, derived_at INT64)\nCREATE REL TABLE PROCEDURE_DERIVES_FROM(FROM ProceduralMemory TO EpisodicMemory, derived_at INT64)\nCREATE REL TABLE CONSOLIDATES(FROM ConsolidatedEpisode TO EpisodicMemory, consolidated_at INT64)\nCREATE REL TABLE ATTENDED_TO(FROM SensoryMemory TO EpisodicMemory, attended_at INT64)\n</code></pre>"},{"location":"kuzu_backend/#schema-kuzubackend-experience-store","title":"Schema: KuzuBackend (Experience Store)","text":"<pre><code>CREATE NODE TABLE Experience(\n    experience_id STRING,\n    agent_name STRING,\n    experience_type STRING,     -- success|failure|pattern|insight\n    context STRING,\n    outcome STRING,\n    confidence DOUBLE,\n    timestamp INT64,\n    metadata STRING,            -- JSON\n    tags STRING,                -- JSON array\n    compressed BOOLEAN,\n    PRIMARY KEY(experience_id)\n)\n\nCREATE REL TABLE SIMILAR_TO(\n    FROM Experience TO Experience,\n    similarity_score DOUBLE\n)\n\nCREATE REL TABLE LEADS_TO(\n    FROM Experience TO Experience,\n    causal_strength DOUBLE\n)\n</code></pre>"},{"location":"kuzu_backend/#query-patterns","title":"Query Patterns","text":""},{"location":"kuzu_backend/#keyword-search","title":"Keyword Search","text":"<pre><code>MATCH (m:SemanticMemory)\nWHERE m.agent_id = $agent_id\n  AND (lower(m.concept) CONTAINS lower($query)\n       OR lower(m.content) CONTAINS lower($query))\nRETURN m.memory_id, m.concept, m.content, m.confidence,\n       m.source_id, m.tags, m.metadata, m.created_at, m.entity_name\nORDER BY m.confidence DESC\nLIMIT $max_nodes\n</code></pre>"},{"location":"kuzu_backend/#entity-centric-retrieval","title":"Entity-Centric Retrieval","text":"<pre><code>MATCH (m:SemanticMemory)\nWHERE m.agent_id = $agent_id\n  AND m.entity_name = $entity_name\nRETURN m.memory_id, m.concept, m.content, m.confidence,\n       m.source_id, m.tags, m.metadata, m.created_at, m.entity_name\nORDER BY m.confidence DESC\nLIMIT $max_nodes\n</code></pre>"},{"location":"kuzu_backend/#similarity-traversal-graph-rag","title":"Similarity Traversal (Graph RAG)","text":"<pre><code>MATCH (m:SemanticMemory)-[e:SIMILAR_TO]-(n:SemanticMemory)\nWHERE m.memory_id IN $seed_ids\n  AND n.agent_id = $agent_id\n  AND e.weight &gt;= $threshold\nRETURN n.memory_id, n.concept, n.content, n.confidence,\n       n.source_id, n.tags, n.metadata, n.created_at, n.entity_name\n</code></pre>"},{"location":"kuzu_backend/#supersedes-chain","title":"Supersedes Chain","text":"<pre><code>MATCH (newer:SemanticMemory)-[:SUPERSEDES]-&gt;(older:SemanticMemory)\nWHERE newer.memory_id IN $seed_ids\n  AND older.agent_id = $agent_id\nRETURN older.memory_id, older.concept, older.content, older.confidence,\n       older.source_id, older.tags, older.metadata, older.created_at,\n       older.entity_name\n</code></pre>"},{"location":"kuzu_backend/#transition-chain","title":"Transition Chain","text":"<pre><code>MATCH (a:SemanticMemory)-[t:TRANSITIONED_TO]-&gt;(b:SemanticMemory)\nWHERE a.memory_id IN $node_ids OR b.memory_id IN $node_ids\nRETURN a.memory_id, b.memory_id, t.from_value, t.to_value,\n       t.turn, t.transition_type\n</code></pre>"},{"location":"kuzu_backend/#performance-characteristics","title":"Performance Characteristics","text":"Operation Complexity Notes Store knowledge O(N) N = recent nodes for similarity comparison Retrieve subgraph O(K + E) K = keyword matches, E = edges traversed Entity lookup O(1) amortized Direct field match Similarity edge creation O(N * M) N = new node tokens, M = existing node tokens Export graph O(V + E) V = vertices, E = edges <p>Typical performance:</p> <ul> <li>Store: ~5-20ms per node (including similarity edge computation)</li> <li>Retrieve: ~2-10ms for keyword + 1-hop traversal</li> <li>Scales well to thousands of nodes per agent</li> </ul>"},{"location":"kuzu_backend/#sqlite-fallback","title":"SQLite Fallback","text":"<p>The <code>SQLiteBackend</code> provides a fallback for environments where Kuzu is not available:</p> <pre><code>from amplihack_memory import MemoryConnector\n\n# Use SQLite instead of Kuzu\nconnector = MemoryConnector(agent_name=\"my-agent\", backend=\"sqlite\")\n</code></pre> <p>Key differences:</p> Feature Kuzu SQLite Storage Graph (nodes + edges) Relational (tables) Search CONTAINS keyword match FTS5 full-text search Relationships Native graph edges Not available Concurrency Single connection WAL mode + thread lock Graph RAG Full support Not available Use case HierarchicalMemory ExperienceStore only <p>The SQLite backend is used by <code>MemoryConnector</code> and <code>ExperienceStore</code> only. The <code>HierarchicalMemory</code> and <code>CognitiveMemory</code> classes always require Kuzu.</p>"}]}